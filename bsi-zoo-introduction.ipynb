{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415d1e64",
   "metadata": {},
   "source": [
    "## Iterative methdos\n",
    "\n",
    "* Should define a function called \"get_estimator\" that returns a **scikit-learn type of pipeline**.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{x}^{(k+1)} \\leftarrow \\arg \\min _{\\boldsymbol{x}}\\|\\boldsymbol{y}-{\\bf L} \\boldsymbol{x}\\|_{2}^{2}+\\lambda \\sum_{i} g(x_{i})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{x}^{(k+1)} \\leftarrow \\arg \\min _{\\boldsymbol{x}}\\|\\boldsymbol{y}-{\\bf L} \\boldsymbol{x}\\|_{2}^{2}+\\lambda \\sum_{i} w_{i}^{(k)}\\left|x_{i}\\right|\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559dc2e",
   "metadata": {},
   "source": [
    "## Single Vector Measurement (SVM) Models\n",
    "\n",
    "### Iterative $\\ell_1$:\n",
    "\\begin{equation}\n",
    "g(x_{i}) = \\log \\left(\\left|x_{i}\\right|+\\epsilon\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "w_{i}^{(k+1)} \\leftarrow\\left[\\left|x_{i}^{(k)}\\right|+\\epsilon\\right]^{-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32cf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda w: np.log(np.abs(w) + eps)\n",
    "gprime = lambda w: 1. / (np.abs(w) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78dfbc",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/GJsY3L7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e72104",
   "metadata": {},
   "source": [
    "### Iterative $\\ell_2$:\n",
    "\\begin{equation}\n",
    "g(x_{i}) = \\log \\left(\\left|x_{i}^2+\\epsilon\\right|\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "w_{i}^{(k+1)} \\leftarrow\\left[\\left(x_{i}^{(k)}\\right)^{2}+\\epsilon\\right]^{-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8c8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda w: np.log(np.abs((w ** 2) + eps))\n",
    "gprime = lambda w: 1. / ((w ** 2) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2073afb",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/AGeUzr6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cdb9d4",
   "metadata": {},
   "source": [
    "### Iterative $\\ell_{0.5}$:\n",
    "\n",
    "\\begin{equation}\n",
    "g(x_{i}) =  \\sqrt{\\left|x_{i}\\right|}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "w_{i}^{(k+1)} \\leftarrow\\left[2\\sqrt{\\left|x_{i}\\right|}+\\epsilon\\right]^{-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d83e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda w: np.sqrt(np.abs(w))\n",
    "gprime = lambda w: 1. / (2. * np.sqrt(np.abs(w)) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba33ad2",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/lP6QKEH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb3d6e",
   "metadata": {},
   "source": [
    "## Iterative Methods - Type II Variants\n",
    "$$\n",
    "\\boldsymbol{x}_{\\mathrm{SBL}}=\\arg \\min _{\\boldsymbol{x}}\\|\\boldsymbol{y}-\\Phi \\boldsymbol{x}\\|_{2}^{2}+\\lambda g_{\\mathrm{SBL}}(\\boldsymbol{x})\n",
    "$$\n",
    "where\n",
    "$$\n",
    "g_{\\mathrm{SBL}}(\\boldsymbol{x}) \\triangleq \\min _{\\gamma \\geq 0} \\boldsymbol{x}^{T} \\Gamma^{-1} \\boldsymbol{x}+\\log \\left|\\alpha I+{\\bf L} \\Gamma {\\bf L}^{T}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c16b3",
   "metadata": {},
   "source": [
    "### Iterative $\\ell_2$ - Type II:\n",
    "\n",
    "\\begin{equation}\n",
    "w_{i}^{(k+1)} \\leftarrow \\left[\\left(x_{i}^{(k)}\\right)^{2}+\\underbrace{\\left(w_{i}^{(k)}\\right)^{-1}-\\left(w_{i}^{(k)}\\right)^{-2}{\\bf L}_{i}^{T}\\left(\\alpha I+{\\bf L}\\widetilde{W}^{(k)}{\\bf L}^{T}\\right)^{-1}{\\bf L}_{i}}\\right]^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "* In comparision to its Type I counterpart, e.g., $w_{i}^{(k+1)} \\leftarrow\\left[\\left(x_{i}^{(k)}\\right)^{2}+\\epsilon\\right]^{-1}$:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\epsilon_{i}^{(k)} \\leftarrow \\left(w_{i}^{(k)}\\right)^{-1}-\\left(w_{i}^{(k)}\\right)^{-2} {\\bf L}_{i}^{T}\\left(\\alpha I+{\\bf L} \\widetilde{W}^{(k)} {\\bf L}^{T}\\right)^{-1}{\\bf L}_{i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53feefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprime(w):\n",
    "    L_T = L.T\n",
    "    n_samples, _ = L.shape\n",
    "\n",
    "    def w_mat(w):\n",
    "        return np.diag(1 / w)\n",
    "\n",
    "    def epsilon_update(L, w, alpha, cov):\n",
    "        noise_cov = cov  # extension of method by importing the noise covariance\n",
    "        proj_source_cov = (L @ w_mat(w)) @ L_T\n",
    "        signal_cov = noise_cov + proj_source_cov\n",
    "        sigmaY_inv = np.linalg.inv(signal_cov)\n",
    "        return np.diag(\n",
    "            w_mat(w)\n",
    "            - np.multiply(\n",
    "                w_mat(w ** 2), np.diag((L_T @ sigmaY_inv) @ L)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return 1.0 / ((w ** 2) + epsilon_update(L, weights, alpha, cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9ff0a",
   "metadata": {},
   "source": [
    "### Iterative $\\ell_1$ - Type II:\n",
    "\\begin{equation}\n",
    "w_{i}^{(k+1)} \\leftarrow\\left[{\\bf L}_{i}^{T}\\left(\\alpha I+{\\bf L} \\widetilde{W}^{(k)} \\tilde{X}^{(k)} {\\bf L}^{T}\\right)^{-1} {\\bf L}_{i}\\right]^{\\frac{1}{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3bed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprime(coef):\n",
    "    L_T = L.T\n",
    "\n",
    "    def w_mat(weights):\n",
    "        return np.diag(1.0 / weights)\n",
    "\n",
    "    x_mat = np.abs(np.diag(coef))\n",
    "    noise_cov = cov\n",
    "    proj_source_cov = (L @ np.dot(w_mat(weights), x_mat)) @ L_T\n",
    "    signal_cov = noise_cov + proj_source_cov\n",
    "    sigmaY_inv = np.linalg.inv(signal_cov)\n",
    "\n",
    "    return np.sqrt(np.diag((L_T @ sigmaY_inv) @ L))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15df42",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ptWWQaB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d967c71",
   "metadata": {},
   "source": [
    "## Methods Comparsision\n",
    "\n",
    "![](https://i.imgur.com/yoNaj1n.png)\n",
    "\n",
    "|                              | EMD (validation) | EMD (test) | Jaccard (validation) | Jaccard (test) | Submission Name     |\n",
    "| ---------------------------- | ---------------- | ---------- | -------------------- | -------------- | ------------------- |\n",
    "| KNN                          |  1.0             |   1.0      |        1.0           |       1.0      | \"knn_resample\"      |\n",
    "| $\\ell_1$                     | 0.271            | 0.269      | 0.710                | 0.731          | \"lasso_lars\"        |\n",
    "| Iterative $\\ell_1$           | 0.238            | 0.241      | 0.639                | 0.669          | \"iterative_L1\"      |\n",
    "| Iterative $\\ell_2$           | 0.253            | 0.256      | 0.641                | 0.669          | \"iterative_L2\"      |\n",
    "| Iterative $\\ell_{0.5}$       | 0.237            | 0.237      | 0.646                | 0.677          | \"iterative_sqrt\"    |\n",
    "| Iterative $\\ell_1$ - Type II | **0.230**        |**0.235**   | **0.636**            | **0.667**      | \"iterative_L1_TypeII\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2473a9",
   "metadata": {},
   "source": [
    "\n",
    "## How about Champagne and Type-II MM methods ? \n",
    "\n",
    "### Quick intro\n",
    "Model the current activity of the brain sources as Gaussian scale mixtures:\n",
    "* Source distribution: $p(\\mathbf{X} \\mid \\Gamma)=\\prod_{t=1}^{T} \\mathcal{N}(0, \\Gamma), \\quad \\Gamma:$ Source covariance with a diagonal structure $\\Gamma=\\operatorname{diag}(\\gamma)=\\operatorname{diag}\\left(\\left[\\gamma_{1}, \\ldots, \\gamma_{N}\\right]^{\\top}\\right)$\n",
    "* Noise distribution: $\\mathbf{E}=[\\mathbf{e}(1), \\ldots, \\mathbf{e}(T)], \\mathbf{e}(t) \\sim \\mathcal{N}(0, \\Lambda), t=1, \\cdots, T$, where $\\Lambda$: Noise covariance with full structure\n",
    "* Measurement distribution: $p(\\mathbf{Y} \\mid \\mathbf{X})=\\prod_{t=1}^{T} \\mathcal{N}(\\mathbf{L} \\mathbf{x}(t), \\mathbf{\\Lambda})$\n",
    "*  Posterior source distribution: $p(\\mathbf{X} \\mid \\mathbf{Y}, \\mathbf{\\Gamma})=\\prod_{t=1}^{T} \\mathcal{N}\\left(\\overline{\\mathbf{x}}(t), \\boldsymbol{\\Sigma}_{\\mathbf{x}}\\right),$ with\n",
    "$$\n",
    "\\overline{\\mathbf{x}}(t)=\\Gamma \\mathbf{L}^{\\top}\\left(\\boldsymbol{\\Sigma}_{\\mathbf{y}}\\right)^{-1} \\mathbf{y}(t) \\quad \\boldsymbol{\\Sigma}_{\\mathbf{x}}=\\boldsymbol{\\Gamma}-\\boldsymbol{\\Gamma} \\mathbf{L}^{\\top}\\left(\\boldsymbol{\\Sigma}_{\\mathbf{y}}\\right)^{-1} \\mathbf{L} \\boldsymbol{\\Gamma} \\quad \\boldsymbol{\\Sigma}_{\\mathbf{y}}=\\boldsymbol{\\Lambda}+\\mathbf{L} \\Gamma \\mathbf{L}^{\\top},\n",
    "$$\n",
    "as a result of learning $\\Gamma$ and $\\Lambda$ (hyper-parameters) through minimizing the negative log-likelihood (Type-II) loss, $-\\log p(\\mathbf{Y} \\mid \\boldsymbol{\\Gamma}, \\boldsymbol{\\Lambda})$\n",
    "$$\n",
    "\\text { Type }-\\text { II Loss : } \\mathcal{L}^{\\text {II }}(\\boldsymbol{\\Gamma}, \\boldsymbol{\\Lambda})=\\log \\left|\\boldsymbol{\\Lambda}+\\mathbf{L} \\Gamma \\mathbf{L}^{\\top}\\right|+\\frac{1}{T} \\sum_{t=1}^{T} \\mathbf{y}(t)^{\\top}\\left(\\mathbf{\\Lambda}+\\mathbf{L} \\Gamma \\mathbf{L}^{\\top}\\right)^{-1} \\mathbf{y}(t)\n",
    "$$\n",
    "\n",
    "### MM Unification Framework\n",
    "\n",
    "![](https://i.imgur.com/V1j5Wj5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60bbde",
   "metadata": {},
   "source": [
    "Implementation of different cases in Python\n",
    "\n",
    "```python\n",
    "if update_mode == 1:\n",
    "    # MacKay fixed point update\n",
    "    numer = gammas ** 2 * np.mean((A * A.conj()).real, axis=1)\n",
    "    denom = gammas * np.sum(L * Sigma_y_invL, axis=0)\n",
    "elif update_mode == 2:\n",
    "    # convex-bounding update\n",
    "    numer = gammas * np.sqrt(np.mean((A * A.conj()).real, axis=1))\n",
    "    denom = np.sum(L * Sigma_y_invL, axis=0)  # sqrt is applied below\n",
    "elif update_mode == 3:\n",
    "    # Expectation Maximization (EM) update\n",
    "    numer = gammas ** 2 * np.mean((A * A.conj()).real, axis=1) \\\n",
    "        + gammas * (1 - gammas * np.sum(L * Sigma_y_invL, axis=0))\n",
    "else:\n",
    "    raise ValueError('Invalid value for update_mode')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f0667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
